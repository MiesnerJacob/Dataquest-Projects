{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting House Sale Prices (Linear Regression)\n",
    "\n",
    "In this project I will work with housing data for the city of Ames, Iowa, United States from 2006 to 2010. The goal of this project is to go through the entire data science workflow of data gathering, data processing, feature engineering, feature selection, modeling, optimizing, and analyzing the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.max_columns = 999\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from pandas_profiling import ProfileReport\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/miesner.jacob/Desktop/DataQuest/datasets/AmesHousing.txt', delimiter = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_features(df):\n",
    "    return df\n",
    "\n",
    "def select_features(df):\n",
    "    return df[['Gr Liv Area','SalePrice']]\n",
    "\n",
    "def train_and_test(df):\n",
    "    train = df[:1460]\n",
    "    test = df[1460:]\n",
    "    \n",
    "    numeric_train = train.select_dtypes(include=['integer', 'float'])\n",
    "    numeric_test = test.select_dtypes(include=['integer', 'float'])\n",
    "    \n",
    "    features = numeric_train.columns.drop(\"SalePrice\")\n",
    "    linear_reg = linear_model.LinearRegression()\n",
    "    linear_reg.fit(train[features], train[\"SalePrice\"])\n",
    "    predictions = linear_reg.predict(test[features])\n",
    "    mse = mean_squared_error(test[\"SalePrice\"], predictions)\n",
    "    rmse = np.sqrt(mse)\n",
    "    \n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'$57,088.25'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing functions\n",
    "transform_df = transform_features(df)\n",
    "filtered_df = select_features(transform_df)\n",
    "rmse_1 = train_and_test(filtered_df)\n",
    "\n",
    "'${:,.2f}'.format(rmse_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "\n",
    "I am going to expand the transform_features function to include:\n",
    "\n",
    "* removing features that we don't want to use in the model, just based on the number of missing values or data leakage\n",
    "* transforming features into the proper format (numerical to categorical, scaling numerical, filling in missing values, etc)\n",
    "* creating new features by combining other features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# profile = ProfileReport(df, title='Pandas Profiling Report')\n",
    "# profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#3 create new features by combining other features\n",
    "years_sold = df['Yr Sold'] - df['Year Built']\n",
    "years_sold[years_sold < 0]\n",
    "years_since_remod = df['Yr Sold'] - df['Year Remod/Add']\n",
    "years_since_remod[years_since_remod < 0]\n",
    "df['Years Before Sale'] = years_sold\n",
    "df['Years Since Remod'] = years_since_remod\n",
    "df = df.drop([1702, 2180, 2181], axis=0)\n",
    "df = df.drop([\"Year Built\", \"Year Remod/Add\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#1 Removing columns with more than 5% missing values and ones that either leak information about saleprice or arent useful\n",
    "pct_null = df.isnull().sum() / len(df)\n",
    "missing_features = pct_null[pct_null > 0.95].index\n",
    "df.drop(missing_features, axis=1, inplace=True)\n",
    "\n",
    "missing = df.isnull().sum()\n",
    "missing = missing[missing > 0]\n",
    "missing = missing.index\n",
    "df[missing]=df[missing].fillna(df[missing].mode().iloc[0])\n",
    "\n",
    "df = df.drop([\"PID\", \"Order\", \"Mo Sold\", \"Sale Condition\", \"Sale Type\", \"Yr Sold\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MS SubClass            int64\n",
       "MS Zoning             object\n",
       "Lot Frontage         float64\n",
       "Lot Area               int64\n",
       "Street                object\n",
       "Alley                 object\n",
       "Lot Shape             object\n",
       "Land Contour          object\n",
       "Utilities             object\n",
       "Lot Config            object\n",
       "Land Slope            object\n",
       "Neighborhood          object\n",
       "Condition 1           object\n",
       "Condition 2           object\n",
       "Bldg Type             object\n",
       "House Style           object\n",
       "Overall Qual           int64\n",
       "Overall Cond           int64\n",
       "Roof Style            object\n",
       "Roof Matl             object\n",
       "Exterior 1st          object\n",
       "Exterior 2nd          object\n",
       "Mas Vnr Type          object\n",
       "Mas Vnr Area         float64\n",
       "Exter Qual            object\n",
       "Exter Cond            object\n",
       "Foundation            object\n",
       "Bsmt Qual             object\n",
       "Bsmt Cond             object\n",
       "Bsmt Exposure         object\n",
       "                      ...   \n",
       "Bsmt Full Bath         int64\n",
       "Bsmt Half Bath         int64\n",
       "Full Bath              int64\n",
       "Half Bath              int64\n",
       "Bedroom AbvGr          int64\n",
       "Kitchen AbvGr          int64\n",
       "Kitchen Qual          object\n",
       "TotRms AbvGrd          int64\n",
       "Functional            object\n",
       "Fireplaces             int64\n",
       "Fireplace Qu          object\n",
       "Garage Type           object\n",
       "Garage Yr Blt        float64\n",
       "Garage Finish         object\n",
       "Garage Cars          float64\n",
       "Garage Area          float64\n",
       "Garage Qual           object\n",
       "Garage Cond           object\n",
       "Paved Drive           object\n",
       "Wood Deck SF           int64\n",
       "Open Porch SF          int64\n",
       "Enclosed Porch         int64\n",
       "3Ssn Porch             int64\n",
       "Screen Porch           int64\n",
       "Pool Area              int64\n",
       "Fence                 object\n",
       "Misc Val               int64\n",
       "SalePrice              int64\n",
       "Years Before Sale      int64\n",
       "Years Since Remod      int64\n",
       "Length: 74, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2 transforming features into the proper format\n",
    "cols = ['Bsmt Full Bath', 'Bsmt Half Bath', 'Half Bath', 'Kitchen AbvGr']\n",
    "df[cols] = df[cols].astype('int')\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets update our transform_features function and see if it improved our model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/miesner.jacob/Desktop/DataQuest/datasets/AmesHousing.txt', delimiter = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_features(df):\n",
    "    years_sold = df['Yr Sold'] - df['Year Built']\n",
    "    years_sold[years_sold < 0]\n",
    "    years_since_remod = df['Yr Sold'] - df['Year Remod/Add']\n",
    "    years_since_remod[years_since_remod < 0]\n",
    "    df['Years Before Sale'] = years_sold\n",
    "    df['Years Since Remod'] = years_since_remod\n",
    "    df = df.drop([1702, 2180, 2181], axis=0)\n",
    "    df = df.drop([\"Year Built\", \"Year Remod/Add\"], axis = 1)\n",
    "    \n",
    "    pct_null = df.isnull().sum() / len(df)\n",
    "    missing_features = pct_null[pct_null > 0.95].index\n",
    "    df.drop(missing_features, axis=1, inplace=True)\n",
    "\n",
    "    missing = df.isnull().sum()\n",
    "    missing = missing[missing > 0]\n",
    "    missing = missing.index\n",
    "    df[missing]=df[missing].fillna(df[missing].mode().iloc[0])\n",
    "\n",
    "    df = df.drop([\"PID\", \"Order\", \"Mo Sold\", \"Sale Condition\", \"Sale Type\", \"Yr Sold\"], axis=1)\n",
    "    cols = ['Bsmt Full Bath', 'Bsmt Half Bath', 'Half Bath', 'Kitchen AbvGr']\n",
    "    df[cols] = df[cols].astype('int')\n",
    "    return df\n",
    "\n",
    "def select_features(df):\n",
    "    return df[['Gr Liv Area','SalePrice']]\n",
    "\n",
    "def train_and_test(df):\n",
    "    train = df[:1460]\n",
    "    test = df[1460:]\n",
    "    \n",
    "    numeric_train = train.select_dtypes(include=['integer', 'float'])\n",
    "    numeric_test = test.select_dtypes(include=['integer', 'float'])\n",
    "    \n",
    "    features = numeric_train.columns.drop(\"SalePrice\")\n",
    "    linear_reg = linear_model.LinearRegression()\n",
    "    linear_reg.fit(train[features], train[\"SalePrice\"])\n",
    "    predictions = linear_reg.predict(test[features])\n",
    "    mse = mean_squared_error(test[\"SalePrice\"], predictions)\n",
    "    rmse = np.sqrt(mse)\n",
    "    \n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Feature Transformation improved the models rmse by 3.18% from $57,088.25 to $55,275.37'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing functions\n",
    "transform_df = transform_features(df)\n",
    "filtered_df = select_features(transform_df)\n",
    "rmse_2 = train_and_test(filtered_df)\n",
    "\n",
    "pct = abs(((rmse_2/rmse_1) - 1) *100)\n",
    "'Feature Transformation improved the models rmse by {pct} from {rmse_1} to {rmse_2}'.format(pct = '{:,.2f}%'.format(pct), rmse_1 = '${:,.2f}'.format(rmse_1), rmse_2 = '${:,.2f}'.format(rmse_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection\n",
    "\n",
    "In performing feature selection I will look to see which columns correlate well with the target feature, which columns need to be converted to categorical types for creation of dummy variables, and which categorical columns have too many unique values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BsmtFin SF 2         0.005891\n",
       "Misc Val             0.015691\n",
       "Yr Sold              0.030569\n",
       "Order                0.031408\n",
       "3Ssn Porch           0.032225\n",
       "Mo Sold              0.035259\n",
       "Bsmt Half Bath       0.035835\n",
       "Low Qual Fin SF      0.037660\n",
       "Pool Area            0.068403\n",
       "MS SubClass          0.085092\n",
       "Overall Cond         0.101697\n",
       "Screen Porch         0.112151\n",
       "Kitchen AbvGr        0.119814\n",
       "Enclosed Porch       0.128787\n",
       "Bedroom AbvGr        0.143913\n",
       "Bsmt Unf SF          0.182855\n",
       "PID                  0.246521\n",
       "Lot Area             0.266549\n",
       "2nd Flr SF           0.269373\n",
       "Bsmt Full Bath       0.276050\n",
       "Half Bath            0.285056\n",
       "Open Porch SF        0.312951\n",
       "Wood Deck SF         0.327143\n",
       "Lot Frontage         0.357318\n",
       "BsmtFin SF 1         0.432914\n",
       "Fireplaces           0.474558\n",
       "TotRms AbvGrd        0.495474\n",
       "Mas Vnr Area         0.508285\n",
       "Garage Yr Blt        0.526965\n",
       "Year Remod/Add       0.532974\n",
       "Years Since Remod    0.534940\n",
       "Full Bath            0.545604\n",
       "Year Built           0.558426\n",
       "Years Before Sale    0.558907\n",
       "1st Flr SF           0.621676\n",
       "Total Bsmt SF        0.632280\n",
       "Garage Area          0.640401\n",
       "Garage Cars          0.647877\n",
       "Gr Liv Area          0.706780\n",
       "Overall Qual         0.799262\n",
       "dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs(df.select_dtypes(include=['int', 'float']).drop(columns=['SalePrice']).corrwith(df['SalePrice'])).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing numerical columns that have a correlation of less than +/-20%\n",
    "numerical_df = transform_df.select_dtypes(include=['int', 'float'])\n",
    "numerical_df = abs(numerical_df.drop(columns=['SalePrice']).corrwith(df['SalePrice']))\n",
    "numerical_df_drop = numerical_df[numerical_df < .20]\n",
    "df = df.drop(numerical_df_drop.index, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting rid od categorical columns with over 10 unique values\n",
    "nominal_features = [\"PID\", \"MS SubClass\", \"MS Zoning\", \"Street\", \"Alley\", \"Land Contour\", \"Lot Config\", \"Neighborhood\", \n",
    "                    \"Condition 1\", \"Condition 2\", \"Bldg Type\", \"House Style\", \"Roof Style\", \"Roof Matl\", \"Exterior 1st\", \n",
    "                    \"Exterior 2nd\", \"Mas Vnr Type\", \"Foundation\", \"Heating\", \"Central Air\", \"Garage Type\", \n",
    "                    \"Misc Feature\", \"Sale Type\", \"Sale Condition\"]\n",
    "    \n",
    "transform_cat_cols = []\n",
    "for col in nominal_features:\n",
    "    if col in df.columns:\n",
    "        transform_cat_cols.append(col)\n",
    "        \n",
    "col_unique_counts = df[transform_cat_cols].nunique()\n",
    "cols_drop = col_unique_counts[col_unique_counts >= 10]\n",
    "df = df.drop(cols_drop.index, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tranforming all string colums to categorical variables and then creating dummy variables\n",
    "categorical_cols = df.select_dtypes(include=['object'])\n",
    "\n",
    "for col in categorical_cols:\n",
    "    df[col] = df[col].astype('category') \n",
    "\n",
    "df = pd.concat([df, pd.get_dummies(df.select_dtypes(include=['category']))], axis=1).drop(categorical_cols,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets update our select_features function and see if it improved our model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/miesner.jacob/Desktop/DataQuest/datasets/AmesHousing.txt', delimiter = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_features(df):\n",
    "    years_sold = df['Yr Sold'] - df['Year Built']\n",
    "    years_sold[years_sold < 0]\n",
    "    years_since_remod = df['Yr Sold'] - df['Year Remod/Add']\n",
    "    years_since_remod[years_since_remod < 0]\n",
    "    df['Years Before Sale'] = years_sold\n",
    "    df['Years Since Remod'] = years_since_remod\n",
    "    df = df.drop([1702, 2180, 2181], axis=0)\n",
    "    df = df.drop([\"Year Built\", \"Year Remod/Add\"], axis = 1)\n",
    "    \n",
    "    pct_null = df.isnull().sum() / len(df)\n",
    "    missing_features = pct_null[pct_null > 0.95].index\n",
    "    df.drop(missing_features, axis=1, inplace=True)\n",
    "\n",
    "    missing = df.isnull().sum()\n",
    "    missing = missing[missing > 0]\n",
    "    missing = missing.index\n",
    "    df[missing]=df[missing].fillna(df[missing].mode().iloc[0])\n",
    "\n",
    "    df = df.drop([\"PID\", \"Order\", \"Mo Sold\", \"Sale Condition\", \"Sale Type\", \"Yr Sold\"], axis=1)\n",
    "    cols = ['Bsmt Full Bath', 'Bsmt Half Bath', 'Half Bath', 'Kitchen AbvGr']\n",
    "    df[cols] = df[cols].astype('int')\n",
    "    return df\n",
    "\n",
    "def select_features(df):\n",
    "    numerical_df = transform_df.select_dtypes(include=['int', 'float'])\n",
    "    numerical_df = abs(numerical_df.drop(columns=['SalePrice']).corrwith(df['SalePrice']))\n",
    "    numerical_df_drop = numerical_df[numerical_df < .20]\n",
    "    df = df.drop(numerical_df_drop.index, axis = 1)\n",
    "    nominal_features = [\"PID\", \"MS SubClass\", \"MS Zoning\", \"Street\", \"Alley\", \"Land Contour\", \"Lot Config\", \"Neighborhood\", \n",
    "                        \"Condition 1\", \"Condition 2\", \"Bldg Type\", \"House Style\", \"Roof Style\", \"Roof Matl\", \"Exterior 1st\", \n",
    "                        \"Exterior 2nd\", \"Mas Vnr Type\", \"Foundation\", \"Heating\", \"Central Air\", \"Garage Type\", \n",
    "                        \"Misc Feature\", \"Sale Type\", \"Sale Condition\"]\n",
    "\n",
    "    transform_cat_cols = []\n",
    "    for col in nominal_features:\n",
    "        if col in df.columns:\n",
    "            transform_cat_cols.append(col)\n",
    "\n",
    "    col_unique_counts = df[transform_cat_cols].nunique()\n",
    "    cols_drop = col_unique_counts[col_unique_counts >= 10]\n",
    "    df = df.drop(cols_drop.index, axis = 1)\n",
    "    categorical_cols = df.select_dtypes(include=['object'])\n",
    "\n",
    "    for col in categorical_cols:\n",
    "        df[col] = df[col].astype('category') \n",
    "\n",
    "    df = pd.concat([df, pd.get_dummies(df.select_dtypes(include=['category']))], axis=1).drop(categorical_cols,axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "def train_and_test(df):\n",
    "    train = df[:1460]\n",
    "    test = df[1460:]\n",
    "    \n",
    "    numeric_train = train.select_dtypes(include=['integer', 'float'])\n",
    "    numeric_test = test.select_dtypes(include=['integer', 'float'])\n",
    "    \n",
    "    features = numeric_train.columns.drop(\"SalePrice\")\n",
    "    linear_reg = linear_model.LinearRegression()\n",
    "    linear_reg.fit(train[features], train[\"SalePrice\"])\n",
    "    predictions = linear_reg.predict(test[features])\n",
    "    mse = mean_squared_error(test[\"SalePrice\"], predictions)\n",
    "    rmse = np.sqrt(mse)\n",
    "    \n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Feature Selection improved the models rmse by an additional 40.59% from $55,275.37 to $32,837.73'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing functions\n",
    "transform_df = transform_features(df)\n",
    "filtered_df = select_features(transform_df)\n",
    "rmse_3 = train_and_test(filtered_df)\n",
    "\n",
    "pct = abs(((rmse_3/rmse_2) - 1) *100)\n",
    "'Feature Selection improved the models rmse by an additional {pct} from {rmse_2} to {rmse_3}'.format(pct = '{:,.2f}%'.format(pct), rmse_2 = '${:,.2f}'.format(rmse_2), rmse_3 = '${:,.2f}'.format(rmse_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding Cross Validation to Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/miesner.jacob/Desktop/DataQuest/datasets/AmesHousing.txt', delimiter = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_features(df):\n",
    "    years_sold = df['Yr Sold'] - df['Year Built']\n",
    "    years_sold[years_sold < 0]\n",
    "    years_since_remod = df['Yr Sold'] - df['Year Remod/Add']\n",
    "    years_since_remod[years_since_remod < 0]\n",
    "    df['Years Before Sale'] = years_sold\n",
    "    df['Years Since Remod'] = years_since_remod\n",
    "    df = df.drop([1702, 2180, 2181], axis=0)\n",
    "    df = df.drop([\"Year Built\", \"Year Remod/Add\"], axis = 1)\n",
    "    \n",
    "    pct_null = df.isnull().sum() / len(df)\n",
    "    missing_features = pct_null[pct_null > 0.95].index\n",
    "    df.drop(missing_features, axis=1, inplace=True)\n",
    "\n",
    "    missing = df.isnull().sum()\n",
    "    missing = missing[missing > 0]\n",
    "    missing = missing.index\n",
    "    df[missing]=df[missing].fillna(df[missing].mode().iloc[0])\n",
    "\n",
    "    df = df.drop([\"PID\", \"Order\", \"Mo Sold\", \"Sale Condition\", \"Sale Type\", \"Yr Sold\"], axis=1)\n",
    "    cols = ['Bsmt Full Bath', 'Bsmt Half Bath', 'Half Bath', 'Kitchen AbvGr']\n",
    "    df[cols] = df[cols].astype('int')\n",
    "    return df\n",
    "\n",
    "def select_features(df):\n",
    "    numerical_df = transform_df.select_dtypes(include=['int', 'float'])\n",
    "    numerical_df = abs(numerical_df.drop(columns=['SalePrice']).corrwith(df['SalePrice']))\n",
    "    numerical_df_drop = numerical_df[numerical_df < .20]\n",
    "    df = df.drop(numerical_df_drop.index, axis = 1)\n",
    "    nominal_features = [\"PID\", \"MS SubClass\", \"MS Zoning\", \"Street\", \"Alley\", \"Land Contour\", \"Lot Config\", \"Neighborhood\", \n",
    "                        \"Condition 1\", \"Condition 2\", \"Bldg Type\", \"House Style\", \"Roof Style\", \"Roof Matl\", \"Exterior 1st\", \n",
    "                        \"Exterior 2nd\", \"Mas Vnr Type\", \"Foundation\", \"Heating\", \"Central Air\", \"Garage Type\", \n",
    "                        \"Misc Feature\", \"Sale Type\", \"Sale Condition\"]\n",
    "\n",
    "    transform_cat_cols = []\n",
    "    for col in nominal_features:\n",
    "        if col in df.columns:\n",
    "            transform_cat_cols.append(col)\n",
    "\n",
    "    col_unique_counts = df[transform_cat_cols].nunique()\n",
    "    cols_drop = col_unique_counts[col_unique_counts >= 10]\n",
    "    df = df.drop(cols_drop.index, axis = 1)\n",
    "    categorical_cols = df.select_dtypes(include=['object'])\n",
    "\n",
    "    for col in categorical_cols:\n",
    "        df[col] = df[col].astype('category') \n",
    "\n",
    "    df = pd.concat([df, pd.get_dummies(df.select_dtypes(include=['category']))], axis=1).drop(categorical_cols,axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "def train_and_test(df, k = 0):\n",
    "    numeric_df = df.select_dtypes(include=['integer', 'float'])\n",
    "    features = df.columns.drop(\"SalePrice\")\n",
    "    linear_reg = linear_model.LinearRegression()\n",
    "    \n",
    "    if k == 0:\n",
    "        train = df[:1460]\n",
    "        test = df[1460:]\n",
    "\n",
    "        numeric_train = train.select_dtypes(include=['integer', 'float'])\n",
    "        numeric_test = test.select_dtypes(include=['integer', 'float'])\n",
    "        linear_reg.fit(train[features], train[\"SalePrice\"])\n",
    "        predictions = linear_reg.predict(test[features])\n",
    "        mse = mean_squared_error(test[\"SalePrice\"], predictions)\n",
    "        rmse = np.sqrt(mse)\n",
    "    elif k == 1:\n",
    "        shuffled_df = df.sample(frac=1)\n",
    "        train = df[:1460]\n",
    "        test = df[1460:]\n",
    "\n",
    "        linear_reg.fit(train[features], train[\"SalePrice\"])\n",
    "        predictions_one = linear_reg.predict(test[features])        \n",
    "        mse_one = mean_squared_error(test[\"SalePrice\"], predictions_one)\n",
    "        rmse_one = mse_one ** (1/2)\n",
    "        \n",
    "        linear_reg.fit(test[features], test[\"SalePrice\"])\n",
    "        predictions_two = linear_reg.predict(train[features])        \n",
    "        mse_two = mean_squared_error(train[\"SalePrice\"], predictions_two)\n",
    "        rmse_two = mse_two ** (1/2)\n",
    "        \n",
    "        rmse = np.mean([rmse_one, rmse_two])\n",
    "    else:\n",
    "        kf = KFold(n_splits=k, shuffle=True)\n",
    "        rmse_values = []\n",
    "        for train_index, test_index, in kf.split(df):\n",
    "            train = df.iloc[train_index]\n",
    "            test = df.iloc[test_index]\n",
    "            linear_reg.fit(train[features], train[\"SalePrice\"])\n",
    "            predictions = linear_reg.predict(test[features])\n",
    "            mse = mean_squared_error(test[\"SalePrice\"], predictions)\n",
    "            rmse = mse ** (1/2)\n",
    "            rmse_values.append(rmse)\n",
    "        rmse = np.mean(rmse_values)\n",
    "        \n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'$32,837.73'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0 folds\n",
    "transform_df = transform_features(df)\n",
    "filtered_df = select_features(transform_df)\n",
    "rmse_0_fold = train_and_test(filtered_df, k=0)\n",
    "\n",
    "'${:,.2f}'.format(rmse_0_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'$29,123.07'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1 folds\n",
    "transform_df = transform_features(df)\n",
    "filtered_df = select_features(transform_df)\n",
    "rmse_1_fold = train_and_test(filtered_df, k=1)\n",
    "\n",
    "'${:,.2f}'.format(rmse_1_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'$28,359.65'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2 folds\n",
    "transform_df = transform_features(df)\n",
    "filtered_df = select_features(transform_df)\n",
    "rmse_2_fold = train_and_test(filtered_df, k=2)\n",
    "\n",
    "'${:,.2f}'.format(rmse_2_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'$27,855.37'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3 folds\n",
    "transform_df = transform_features(df)\n",
    "filtered_df = select_features(transform_df)\n",
    "rmse_3_fold = train_and_test(filtered_df, k=3)\n",
    "\n",
    "'${:,.2f}'.format(rmse_3_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'$26,979.97'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 10 folds\n",
    "transform_df = transform_features(df)\n",
    "filtered_df = select_features(transform_df)\n",
    "rmse_10_fold = train_and_test(filtered_df, k=10)\n",
    "\n",
    "'${:,.2f}'.format(rmse_10_fold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the RMSE gets lower with more k-folds. Cross-validation does not improve accuracy but it helps give a better depiction of how accurate your model truley is.\n",
    "\n",
    "This project shows an end to end data science workflow on Linear Regression (Ordinary Least Squares). This project really highlights the importance of feature engineering and feature selection. These are crucial steps in the data science workflow that cannot be neglected because they make sure that your models are given the best input possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
